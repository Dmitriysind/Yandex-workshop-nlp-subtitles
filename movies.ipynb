{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pysrt\n",
    "# %pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Lampq\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostClassifier\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# import required module\n",
    "import os\n",
    "import pysrt\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from pymystem3 import Mystem\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "kaggle_df = pd.read_csv('database/kaggle/cefr_leveled_texts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi!\\nI've been meaning to write for ages and f...</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>﻿It was not so much how hard people found the ...</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Keith recently came back from a trip to Chicag...</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Griffith Observatory is a planetarium, and...</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-LRB- The Hollywood Reporter -RRB- It's offici...</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0  Hi!\\nI've been meaning to write for ages and f...    B2\n",
       "1  ﻿It was not so much how hard people found the ...    B2\n",
       "2  Keith recently came back from a trip to Chicag...    B2\n",
       "3  The Griffith Observatory is a planetarium, and...    B2\n",
       "4  -LRB- The Hollywood Reporter -RRB- It's offici...    B2"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_excel('database/english_score/movies_labels.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign directory\n",
    "directory_A2 = 'database/english_score/Subtitles_all/A2'\n",
    "directory_B1 = 'database/english_score/Subtitles_all/B1'\n",
    "directory_B2 = 'database/english_score/Subtitles_all/B2'\n",
    "directory_C1 = 'database/english_score/Subtitles_all/C1'\n",
    "directory_test = 'database/english_score/Subtitles_all/Subtitles'\n",
    "\n",
    "path_dict = {}\n",
    "path_dict['A2'] = directory_A2\n",
    "path_dict['B1'] = directory_B1\n",
    "path_dict['B2'] = directory_B2\n",
    "path_dict['C1'] = directory_C1\n",
    "path_dict['test'] = directory_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_from_file(file):\n",
    "    text = []\n",
    "\n",
    "    for sub in file:\n",
    "        text.append(sub.text)\n",
    "    \n",
    "    return ''.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_from_folder(folder):\n",
    "    folder_text = []\n",
    "    for filename in os.scandir(folder):\n",
    "        if filename.is_file():\n",
    "            file_srt = pysrt.open(filename.path, encoding='iso-8859-1')\n",
    "            folder_text.append(get_text_from_file(file_srt))\n",
    "\n",
    "    return folder_text        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A2\n",
      "database/english_score/Subtitles_all/A2\n",
      "B1\n",
      "database/english_score/Subtitles_all/B1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B2\n",
      "database/english_score/Subtitles_all/B2\n",
      "C1\n",
      "database/english_score/Subtitles_all/C1\n",
      "test\n",
      "database/english_score/Subtitles_all/Subtitles\n"
     ]
    }
   ],
   "source": [
    "df_dict = {}\n",
    "for folder in path_dict:\n",
    "    print(folder)\n",
    "    print(path_dict[folder])\n",
    "    df_dict[folder] = get_text_from_folder(path_dict[folder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df_dict.items(), columns=['target', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2</td>\n",
       "      <td>[( bugs chittering )( brakes squeak )- ( engin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B1</td>\n",
       "      <td>[I need a father who's a role model,\\nnot some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B2</td>\n",
       "      <td>[[match snaps, fizzles][fire crackling][puffs]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C1</td>\n",
       "      <td>[[TELEGRAPH MACHINE BEEPING][TRAIN WHISTLE BLO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test</td>\n",
       "      <td>[&lt;font color=\"#ffff80\"&gt;&lt;b&gt;Fixed &amp; Synced by bo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                               text\n",
       "0     A2  [( bugs chittering )( brakes squeak )- ( engin...\n",
       "1     B1  [I need a father who's a role model,\\nnot some...\n",
       "2     B2  [[match snaps, fizzles][fire crackling][puffs]...\n",
       "3     C1  [[TELEGRAPH MACHINE BEEPING][TRAIN WHISTLE BLO...\n",
       "4   test  [<font color=\"#ffff80\"><b>Fixed & Synced by bo..."
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.explode('text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Movie</th>\n",
       "      <th>Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10_Cloverfield_lane(2016)</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10_things_I_hate_about_you(1999)</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A_knights_tale(2001)</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A_star_is_born(2018)</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Aladdin(1992)</td>\n",
       "      <td>A2/A2+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                             Movie   Level\n",
       "0   0         10_Cloverfield_lane(2016)      B1\n",
       "1   1  10_things_I_hate_about_you(1999)      B1\n",
       "2   2              A_knights_tale(2001)      B2\n",
       "3   3              A_star_is_born(2018)      B2\n",
       "4   4                     Aladdin(1992)  A2/A2+"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    re_text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    split_text = re_text.split()\n",
    "    join_text = \" \".join(split_text)\n",
    "    return join_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_stopwords(text):\n",
    "#     words = text.split()\n",
    "#     return ' '.join([word.lower() for word in words if not word.lower() in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"text\"].apply(clear_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['text'] = df['text'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    bugs chittering brakes squeak engine stops tru...\n",
       "0    birds chirping bugs chittering boy mom right h...\n",
       "0    thunder rumbling merle that s right you heard ...\n",
       "0    birds chirping what nothing it s not nothing i...\n",
       "0    walkie talkie squawks rick morgan i don t know...\n",
       "                           ...                        \n",
       "4    i what am i doing i i with my life i i i m so ...\n",
       "4    music no one s complained music there s the la...\n",
       "4    i oh my god i i it s full on double rainbow al...\n",
       "4    lucy i okay there are two things that i i i re...\n",
       "4    fear treachery bloodlust thousands of years ag...\n",
       "Name: text, Length: 278, dtype: object"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = ['A2', 'B1', 'B2', 'C1']\n",
    "df_train = df.loc[df['target'].isin(target)]\n",
    "df_test = df.loc[df['target'] == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['A2', 'B1', 'B2', 'C1'], dtype=object), array(['test'], dtype=object))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['target'].unique(), df_test['target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_subs = df_train['text']\n",
    "y_subs = df_train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B1', 'B2', 'A2/A2+', 'C1', 'B1, B2', 'A2/A2+, B1', 'A2'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies['Level'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_target(x):    \n",
    "    if x == 'A2/A2+': \n",
    "        return 'A2'\n",
    "    if x == 'B1, B2': \n",
    "        return 'B2'\n",
    "    if x == 'A2/A2+, B1': \n",
    "        return 'B1'\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_target(x):\n",
    "    if x == 'A1': \n",
    "        return 0\n",
    "    if x == 'A2': \n",
    "        return 1\n",
    "    if x == 'B1': \n",
    "        return 2\n",
    "    if x == 'B2': \n",
    "        return 3\n",
    "    if x == 'C1': \n",
    "        return 4\n",
    "    if x == 'C2': \n",
    "        return 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_movies = []\n",
    "\n",
    "for filename in os.scandir(directory_test):\n",
    "    if filename.is_file():\n",
    "        test_movies.append(os.path.basename(filename).split('.')[0].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_lower(x):\n",
    "    return x.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['Movie'] = movies['Movie'].apply(df_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_targets = []\n",
    "\n",
    "for test_movie in test_movies:\n",
    "    level = movies[movies['Movie'] == test_movie]['Level'].values\n",
    "\n",
    "    if len(level) > 0:\n",
    "        test_targets.append(level[0])\n",
    "    else:\n",
    "        test_targets.append('')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test['text'].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lampq\\AppData\\Local\\Temp\\ipykernel_15656\\2326337551.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['target'] = test_targets\n"
     ]
    }
   ],
   "source": [
    "df_test['target'] = test_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test[df_test['target'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test['text'].to_frame()\n",
    "y_test = df_test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B1</td>\n",
       "      <td>font color ffff b fixed synced by bozxphd enjo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B1</td>\n",
       "      <td>hey i ll be right with you so cameron here you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A2/A2+</td>\n",
       "      <td>i oh i come from a land from a faraway place i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A2/A2+</td>\n",
       "      <td>captioning made possible by mgm home entertain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A2/A2+</td>\n",
       "      <td>indistinct conversation all laughing mama tany...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text\n",
       "4      B1  font color ffff b fixed synced by bozxphd enjo...\n",
       "4      B1  hey i ll be right with you so cameron here you...\n",
       "4  A2/A2+  i oh i come from a land from a faraway place i...\n",
       "4  A2/A2+  captioning made possible by mgm home entertain...\n",
       "4  A2/A2+  indistinct conversation all laughing mama tany..."
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106, 106)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B1', 'A2/A2+', 'B2', 'C1', 'B1, B2', 'A2/A2+, B1'], dtype=object)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ДАТАСЕТ KAGGLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_df = pd.read_csv('database/kaggle/cefr_leveled_texts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi!\\nI've been meaning to write for ages and f...</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>﻿It was not so much how hard people found the ...</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Keith recently came back from a trip to Chicag...</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Griffith Observatory is a planetarium, and...</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-LRB- The Hollywood Reporter -RRB- It's offici...</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0  Hi!\\nI've been meaning to write for ages and f...    B2\n",
       "1  ﻿It was not so much how hard people found the ...    B2\n",
       "2  Keith recently came back from a trip to Chicag...    B2\n",
       "3  The Griffith Observatory is a planetarium, and...    B2\n",
       "4  -LRB- The Hollywood Reporter -RRB- It's offici...    B2"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A1    288\n",
       "B2    286\n",
       "A2    272\n",
       "C1    241\n",
       "B1    205\n",
       "C2    202\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_kaggle= kaggle_df['text'].to_frame()\n",
    "y_kaggle = kaggle_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_kaggle['text'] = X_kaggle['text'].apply(clear_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_subs = df_train['text']\n",
    "y_subs = df_train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1494, 1), (163,))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_kaggle.shape, X_subs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X_kaggle, X_subs.to_frame()])\n",
    "y = pd.concat([y_kaggle, y_subs]).apply(normalize_target)\n",
    "y_nun = y.apply(change_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B2    393\n",
       "A1    288\n",
       "A2    278\n",
       "C1    274\n",
       "B1    222\n",
       "C2    202\n",
       "dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1657, 1), (1657,))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_kaggle_train, X_kaggle_val, y_kaggle_train, y_kaggle_val =  train_test_split(X, y, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1242, 415, 1242, 415)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_kaggle_train), len(X_kaggle_val), len(y_kaggle_train), len(y_kaggle_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_prep_text = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
    "bert_encoding = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_embedding(text):\n",
    "    prep_text = bert_prep_text(text)\n",
    "    return bert_encoding(prep_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Exception encountered when calling layer \"keras_layer_8\" \"                 f\"(type KerasLayer).\n\nGraph execution error:\n\nOOM when allocating tensor with shape[1242,16,128,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node transformer/layer_0/self_attention/einsum/Einsum}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_restored_function_body_155669]\n\nCall arguments received by layer \"keras_layer_8\" \"                 f\"(type KerasLayer):\n  • inputs={'input_word_ids': 'tf.Tensor(shape=(1242, 128), dtype=int32)', 'input_type_ids': 'tf.Tensor(shape=(1242, 128), dtype=int32)', 'input_mask': 'tf.Tensor(shape=(1242, 128), dtype=int32)'}\n  • training=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Lampq\\projects\\job-interview-projects\\nlp_movies\\movies.ipynb Cell 52\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Lampq/projects/job-interview-projects/nlp_movies/movies.ipynb#Y133sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m text_train_embeddings \u001b[39m=\u001b[39m get_text_embedding(X_kaggle_train[\u001b[39m\"\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m\"\u001b[39;49m])[\u001b[39m\"\u001b[39m\u001b[39msequence_output\u001b[39m\u001b[39m\"\u001b[39m][:,\u001b[39m0\u001b[39m,:]\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lampq/projects/job-interview-projects/nlp_movies/movies.ipynb#Y133sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m text_val_embeddings \u001b[39m=\u001b[39m get_text_embedding(X_kaggle_val[\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m])[\u001b[39m\"\u001b[39m\u001b[39msequence_output\u001b[39m\u001b[39m\"\u001b[39m][:,\u001b[39m0\u001b[39m,:]\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lampq/projects/job-interview-projects/nlp_movies/movies.ipynb#Y133sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m text_test_embeddings \u001b[39m=\u001b[39m get_text_embedding(X_test[\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m])[\u001b[39m\"\u001b[39m\u001b[39msequence_output\u001b[39m\u001b[39m\"\u001b[39m][:,\u001b[39m0\u001b[39m,:]\u001b[39m.\u001b[39mnumpy()\n",
      "\u001b[1;32mc:\\Users\\Lampq\\projects\\job-interview-projects\\nlp_movies\\movies.ipynb Cell 52\u001b[0m in \u001b[0;36mget_text_embedding\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lampq/projects/job-interview-projects/nlp_movies/movies.ipynb#Y133sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_text_embedding\u001b[39m(text):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lampq/projects/job-interview-projects/nlp_movies/movies.ipynb#Y133sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     prep_text \u001b[39m=\u001b[39m bert_prep_text(text)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Lampq/projects/job-interview-projects/nlp_movies/movies.ipynb#Y133sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m bert_encoding(prep_text)\n",
      "File \u001b[1;32mc:\\Python3100\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Python3100\\lib\\site-packages\\tensorflow_hub\\keras_layer.py:237\u001b[0m, in \u001b[0;36mKerasLayer.call\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m    234\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    235\u001b[0m     \u001b[39m# Behave like BatchNormalization. (Dropout is different, b/181839368.)\u001b[39;00m\n\u001b[0;32m    236\u001b[0m     training \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m--> 237\u001b[0m   result \u001b[39m=\u001b[39m smart_cond\u001b[39m.\u001b[39;49msmart_cond(training,\n\u001b[0;32m    238\u001b[0m                                  \u001b[39mlambda\u001b[39;49;00m: f(training\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m),\n\u001b[0;32m    239\u001b[0m                                  \u001b[39mlambda\u001b[39;49;00m: f(training\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m))\n\u001b[0;32m    241\u001b[0m \u001b[39m# Unwrap dicts returned by signatures.\u001b[39;00m\n\u001b[0;32m    242\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_key:\n",
      "File \u001b[1;32mc:\\Python3100\\lib\\site-packages\\tensorflow_hub\\keras_layer.py:239\u001b[0m, in \u001b[0;36mKerasLayer.call.<locals>.<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    234\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    235\u001b[0m     \u001b[39m# Behave like BatchNormalization. (Dropout is different, b/181839368.)\u001b[39;00m\n\u001b[0;32m    236\u001b[0m     training \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    237\u001b[0m   result \u001b[39m=\u001b[39m smart_cond\u001b[39m.\u001b[39msmart_cond(training,\n\u001b[0;32m    238\u001b[0m                                  \u001b[39mlambda\u001b[39;00m: f(training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m),\n\u001b[1;32m--> 239\u001b[0m                                  \u001b[39mlambda\u001b[39;00m: f(training\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m))\n\u001b[0;32m    241\u001b[0m \u001b[39m# Unwrap dicts returned by signatures.\u001b[39;00m\n\u001b[0;32m    242\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_key:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Exception encountered when calling layer \"keras_layer_8\" \"                 f\"(type KerasLayer).\n\nGraph execution error:\n\nOOM when allocating tensor with shape[1242,16,128,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node transformer/layer_0/self_attention/einsum/Einsum}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_restored_function_body_155669]\n\nCall arguments received by layer \"keras_layer_8\" \"                 f\"(type KerasLayer):\n  • inputs={'input_word_ids': 'tf.Tensor(shape=(1242, 128), dtype=int32)', 'input_type_ids': 'tf.Tensor(shape=(1242, 128), dtype=int32)', 'input_mask': 'tf.Tensor(shape=(1242, 128), dtype=int32)'}\n  • training=None"
     ]
    }
   ],
   "source": [
    "# text_train_embeddings = get_text_embedding(X_kaggle_train[\"text\"])[\"sequence_output\"][:,0,:].numpy()\n",
    "# text_val_embeddings = get_text_embedding(X_kaggle_val[\"text\"])[\"sequence_output\"][:,0,:].numpy()\n",
    "text_test_embeddings = get_text_embedding(X_test[\"text\"])[\"sequence_output\"][:,0,:].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1242, 256), (415, 256), (106, 256))"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_train_embeddings.shape, text_val_embeddings.shape, text_test_embeddings.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_words = set(stopwords.words('english'))\n",
    "# tf_idf = TfidfVectorizer(stop_words=list(stop_words))\n",
    "\n",
    "# X_kaggle_tfidf_train = tf_idf.fit_transform(X_kaggle_train['text'])\n",
    "# X_kaggle_tfidf_val = tf_idf.transform(X_kaggle_val['text'])\n",
    "# X_tfidf_test = tf_idf.transform(X_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_kaggle_tfidf_train.shape, X_kaggle_tfidf_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = CatBoostRegressor(\n",
    "#                 random_seed=1,\n",
    "#                 iterations=700,    \n",
    "#                 task_type='GPU',\n",
    "#                 data_partition='DocParallel', \n",
    "#                 od_type='Iter',\n",
    "#                 # od_wait=20,\n",
    "#                 # text_features=['text'],\n",
    "#                 metric_period=500,\n",
    "#                 learning_rate=0.2,\n",
    "#                 rsm=1,\n",
    "#                 loss_function=\"RMSE\",\n",
    "#                 eval_metric='RMSE'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(\n",
    "#     X_kaggle_tfidf_train, y_kaggle_train,\n",
    "#     eval_set=(X_kaggle_val, y_kaggle_val),\n",
    "#     cat_features=None,\n",
    "#     verbose=True,\n",
    "#     # plot=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cls = CatBoostClassifier(\n",
    "                random_seed=1,\n",
    "                iterations=5000,    \n",
    "                task_type='GPU',\n",
    "                data_partition='DocParallel', \n",
    "                # od_type='Iter',\n",
    "                # od_wait=20,\n",
    "                # text_features=['text'],\n",
    "                metric_period=500,\n",
    "                learning_rate=0.001,\n",
    "                rsm=1,\n",
    "                loss_function=\"MultiClass\",\n",
    "                eval_metric='Accuracy',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: less than 75% gpu memory available for training. Free: 710.5546875 Total: 6143.5625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.4983897\ttest: 0.3421687\tbest: 0.3421687 (0)\ttotal: 26.8ms\tremaining: 2m 13s\n",
      "500:\tlearn: 0.6264090\ttest: 0.4337349\tbest: 0.4337349 (500)\ttotal: 6.44s\tremaining: 57.9s\n",
      "1000:\tlearn: 0.6594203\ttest: 0.4385542\tbest: 0.4385542 (1000)\ttotal: 12.7s\tremaining: 50.8s\n",
      "1500:\tlearn: 0.6876006\ttest: 0.4457831\tbest: 0.4457831 (1500)\ttotal: 19s\tremaining: 44.3s\n",
      "2000:\tlearn: 0.7206119\ttest: 0.4530120\tbest: 0.4530120 (2000)\ttotal: 25.2s\tremaining: 37.8s\n",
      "2500:\tlearn: 0.7552335\ttest: 0.4578313\tbest: 0.4578313 (2500)\ttotal: 31.4s\tremaining: 31.4s\n",
      "3000:\tlearn: 0.7818035\ttest: 0.4626506\tbest: 0.4626506 (3000)\ttotal: 37.8s\tremaining: 25.2s\n",
      "3500:\tlearn: 0.8140097\ttest: 0.4650602\tbest: 0.4650602 (3500)\ttotal: 44s\tremaining: 18.9s\n",
      "4000:\tlearn: 0.8397746\ttest: 0.4698795\tbest: 0.4698795 (4000)\ttotal: 50.3s\tremaining: 12.6s\n",
      "4500:\tlearn: 0.8639291\ttest: 0.4795181\tbest: 0.4795181 (4500)\ttotal: 56.8s\tremaining: 6.29s\n",
      "4999:\tlearn: 0.8792271\ttest: 0.4843373\tbest: 0.4843373 (4999)\ttotal: 1m 2s\tremaining: 0us\n",
      "bestTest = 0.4843373494\n",
      "bestIteration = 4999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1b9dc2a5b40>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cls.fit(\n",
    "    text_train_embeddings, y_kaggle_train,\n",
    "    eval_set=(text_val_embeddings, y_kaggle_val),\n",
    "    verbose=True,\n",
    "    # plot=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# РЕЗУЛЬТАТЫ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "для классификатора:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16037735849056603"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_cls = model_cls.predict(text_test_embeddings)\n",
    "accuracy_score(y_test, y_pred_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ff' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Lampq\\projects\\job-interview-projects\\nlp_movies\\movies.ipynb Cell 64\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Lampq/projects/job-interview-projects/nlp_movies/movies.ipynb#Y115sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m ff\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ff' is not defined"
     ]
    }
   ],
   "source": [
    "ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "CatBoostError",
     "evalue": "There is no trained model to use predict(). Use fit() to train model. Then use this method.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Lampq\\projects\\job-interview-projects\\nlp_movies\\movies.ipynb Cell 62\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Lampq/projects/job-interview-projects/nlp_movies/movies.ipynb#X63sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(X_tfidf_test)\n",
      "File \u001b[1;32mc:\\Python3100\\lib\\site-packages\\catboost\\core.py:5635\u001b[0m, in \u001b[0;36mCatBoostRegressor.predict\u001b[1;34m(self, data, prediction_type, ntree_start, ntree_end, thread_count, verbose, task_type)\u001b[0m\n\u001b[0;32m   5633\u001b[0m \u001b[39mif\u001b[39;00m prediction_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   5634\u001b[0m     prediction_type \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_default_prediction_type()\n\u001b[1;32m-> 5635\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predict(data, prediction_type, ntree_start, ntree_end, thread_count, verbose, \u001b[39m'\u001b[39;49m\u001b[39mpredict\u001b[39;49m\u001b[39m'\u001b[39;49m, task_type)\n",
      "File \u001b[1;32mc:\\Python3100\\lib\\site-packages\\catboost\\core.py:2458\u001b[0m, in \u001b[0;36mCatBoost._predict\u001b[1;34m(self, data, prediction_type, ntree_start, ntree_end, thread_count, verbose, parent_method_name, task_type)\u001b[0m\n\u001b[0;32m   2456\u001b[0m \u001b[39mif\u001b[39;00m verbose \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2457\u001b[0m     verbose \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 2458\u001b[0m data, data_is_single_object \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_predict_input_data(data, parent_method_name, thread_count)\n\u001b[0;32m   2459\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_prediction_type(prediction_type)\n\u001b[0;32m   2461\u001b[0m predictions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_base_predict(data, prediction_type, ntree_start, ntree_end, thread_count, verbose, task_type)\n",
      "File \u001b[1;32mc:\\Python3100\\lib\\site-packages\\catboost\\core.py:2434\u001b[0m, in \u001b[0;36mCatBoost._process_predict_input_data\u001b[1;34m(self, data, parent_method_name, thread_count, label)\u001b[0m\n\u001b[0;32m   2432\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_process_predict_input_data\u001b[39m(\u001b[39mself\u001b[39m, data, parent_method_name, thread_count, label\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   2433\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_fitted() \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtree_count_ \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 2434\u001b[0m         \u001b[39mraise\u001b[39;00m CatBoostError((\u001b[39m\"\u001b[39m\u001b[39mThere is no trained model to use \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m(). \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2435\u001b[0m                              \u001b[39m\"\u001b[39m\u001b[39mUse fit() to train model. Then use this method.\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mformat(parent_method_name))\n\u001b[0;32m   2436\u001b[0m     is_single_object \u001b[39m=\u001b[39m _is_data_single_object(data)\n\u001b[0;32m   2437\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data, Pool):\n",
      "\u001b[1;31mCatBoostError\u001b[0m: There is no trained model to use predict(). Use fit() to train model. Then use this method."
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_target_to_cat(x):    \n",
    "    if x > 0 and x <= 0.5: \n",
    "        return 'A1'\n",
    "    if x > 0.5 and x < 2: \n",
    "        return 'A2'\n",
    "    if x >= 2 and x < 2.5: \n",
    "        return 'B1'\n",
    "    if x >= 2.5 and x < 3.5: \n",
    "        return 'B2'\n",
    "    if x >= 3.5 and x < 4.5: \n",
    "        return 'C1'\n",
    "    else: \n",
    "        return 'C2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B2    70\n",
       "B1    26\n",
       "A2     5\n",
       "C1     5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 769,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = pd.Series(y_pred).apply(num_target_to_cat)\n",
    "y_pred.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B1    38\n",
       "B2    37\n",
       "A2    25\n",
       "C1     6\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 771,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = df_test['target'].apply(normalize_target)\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4716981132075472"
      ]
     },
     "execution_count": 772,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
